{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In 2018, the e-commerce site Rakuten ran a public data challenge that asked data scientists to develop a model to classify products given a text description of that product. This notebook shows an early attempt to address this challenge. Included in this work is data analysis, discussion of performance metrics, implementation of a simple text classifier and some classifier parameter tuning. This work is an early version of how an overall project might look, so we included several recommendations for future work.\n",
    "\n",
    "While this work is derived from many sources, many of the methods and approaches were inspired by the scikit learn tutorial on working with text data: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "The training data, data used to train the machine leaning model, consists of 800,000 records. Each record has only two fields: a description of the product and the product's category. The fields are both strings. The following subsections take a closer look at the labels (product category) and features (product description). Minor cleaning checked that there were no invalid (np.nan or None) values in either the description or category fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  800000\n",
      "Number of columns:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cat_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Replacement Viewsonic VG710 LCD Monitor 48Watt...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...</td>\n",
       "      <td>3292&gt;1370&gt;4767&gt;3975&gt;1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonjour</td>\n",
       "      <td>2296&gt;3597&gt;2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Pack 6V 12Ah  Eaton POWERRITE PRO II 2400 ...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generations Small Side Table White</td>\n",
       "      <td>4015&gt;3636&gt;1319&gt;1409&gt;3606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                  cat_full\n",
       "0  Replacement Viewsonic VG710 LCD Monitor 48Watt...             3292>114>1231\n",
       "1  HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...  3292>1370>4767>3975>1420\n",
       "2                                            Bonjour            2296>3597>2989\n",
       "3  Two Pack 6V 12Ah  Eaton POWERRITE PRO II 2400 ...             3292>114>1231\n",
       "4                 Generations Small Side Table White  4015>3636>1319>1409>3606"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv('https://github.com/up-lab/rakuten-data-challenge/raw/master/rdc-catalog-train.tsv', header=None, names=['description', 'cat_full'], sep='\\t', )\n",
    "\n",
    "#print some basic information about data\n",
    "print('Number of rows: ', train_data.shape[0])\n",
    "print('Number of columns: ', train_data.shape[1])\n",
    "\n",
    "#look at the data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cat_1'] = train_data['cat_full'].apply(lambda x: x.split('>')[0])\n",
    "train_data['cat_2'] = train_data['cat_full'].apply(lambda x: x.split('>')[1] if (len(x.split('>'))>1) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before cleaning:  800000\n",
      "Number of rows after cleaning:  800000\n"
     ]
    }
   ],
   "source": [
    "#basic cleaning, remove any rows that don't have values in the decsription or cat_1 fields (leaving those with\n",
    "#missing cat_2 for now)\n",
    "print('Number of rows before cleaning: ', train_data.shape[0])\n",
    "train_data.dropna(subset=['description','cat_1'], inplace=True)\n",
    "print('Number of rows after cleaning: ', train_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels\n",
    "\n",
    "The category field is ultimately the labels. The categories are hierarchical with each level separated by a \">\" character. Not all labels consist of the same number of levels. Number of category levels range from 1 to 8 with a mean of 4. To simplify this work, we will focus on classification of the first two levels only and leave further classification to future work. There are 14 unique first level categories and 109 unique second level categories. Further there are 109 unique first+second level categories, meaning there are no shared second level categories with first level categories (e.g. if A>1 and B>2 are categories, \"1\" always mapped back to \"A\" and 2 always mapped back to \"B\").\n",
    "\n",
    "Finally, we take a look at how balanced the data is for the first level category. It is not a very balanced dataset, with 2/14 of the first level categories composing more than 50% of the dataset. This may have implications on certain classifier performance, perhaps showing overwhelming preference to classifying those more prevalent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of categories:  1\n",
      "Maximum number of categories:  8\n",
      "Mean number of categories:  4.0131475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the distribution for teh category mappings\n",
    "num_categories = train_data['cat_full'].apply(lambda x: len(x.split('>')))\n",
    "print('Minimum number of categories: ', min(num_categories))\n",
    "print('Maximum number of categories: ', max(num_categories))\n",
    "print('Mean number of categories: ', np.mean(num_categories))\n",
    "\n",
    "\n",
    "plt.hist(num_categories, align='left', bins=[x for x in range(max(num_categories))])\n",
    "plt.xlabel('Number of category levels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of first level distinct categories:  14\n",
      "Number of second level distinct categories:  109\n",
      "Number of first+second level distinct categories:  109\n"
     ]
    }
   ],
   "source": [
    "#look at numer of categories\n",
    "print('Number of first level distinct categories: ', len(train_data['cat_1'].unique()))\n",
    "print('Number of second level distinct categories: ', len(train_data['cat_2'].unique()))\n",
    "#double checking there are no second level category mappings that are shared between first levels\n",
    "#(e.g. 1>a and 2>a)\n",
    "print('Number of first+second level distinct categories: ', len(train_data.groupby(['cat_1', 'cat_2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_1\n",
       "1208    0.001288\n",
       "1395    0.023559\n",
       "1608    0.106942\n",
       "2075    0.025108\n",
       "2199    0.120892\n",
       "2296    0.035515\n",
       "3093    0.006372\n",
       "3292    0.251181\n",
       "3625    0.036946\n",
       "3730    0.010141\n",
       "4015    0.335369\n",
       "4238    0.029411\n",
       "4564    0.007060\n",
       "92      0.010215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at how balanaced the training set is\n",
    "train_data.groupby('cat_1').apply(len)/len(train_data['cat_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "\n",
    "The description field will provide the basis for the feature(s) in our machine learning model. Each description is a short collection of \"words\" any about the product. Words here are actually tokens, defined by the scikit learn toolkit tokenizer, which is basically smaller groups of characters identifiable meaning (usually words). The entry descriptions' length range from 0 to 52 words with a mean of 10.6 and a standard deviation of 4.7. This led to the decision to use a bag of words model, a model whereby words and their frequency are the system's features. There are often few enough words in the descriptions, that the machine learning model will likely be classifying categories from previously encountered words.\n",
    "\n",
    "\n",
    "The scikit learn tokenizer is used convert the description text into tokens. We first apply this to a small sample set to gain a better understanding of how the tokenizer constructs the features. We see that the tokenizer works by breaking up all the tokens in all n training data points into m tokens. Then, it constructs an nxm matrix which is the count of every possible token in each training data point. You can normalize beyond simple word counts to account for super common words among and within different entries using TF-IDF (term frequency times inverse document frequency). Each of the n training points is so short however, that it's unclear how helpful this normalization would be and is thus left to future work.\n",
    "\n",
    "After gaining some understanding of how the tokenizer functions, we broadened the analysis to look at the entire tokenized training set. Without any further data processing, the training set contains 427,297 total tokens. Looking at the token frequency across the training set, we see that tokens had a mean count of ~20 tokens with a standard deviation of ~510 tokens, meaning some high frequency words are much higher frequency than others and skewing that standard deviation pretty high. There are a couple potential data processing measures we could take here such as:\n",
    "\n",
    "- Removing stop words: By removing common words in the English language, such as \"the\", we may be able to reduce and enrich the feature space.\n",
    "- Using n-grams: Small groups of tokens, rather than single tokens, may contain more context. For example, we show that \"black\" is a high frequency word. But using pairs of words like \"black beans\" and \"black notebook\" we may give the features more context.\n",
    "- Stemming/Lemmatizing: Grouping words together with similar meanings would help reduce the size of and enrich the feature space. An example of stemming/lemmatizing would be mapping \"battery\" and \"batteries\" to the same token.\n",
    "- Translation: A peek at the tokens below reveals that there are some entries with non-English words. Performing a translation operation to English such that all entries are the same language would help build a better training set.\n",
    "\n",
    "The analysis below explores removing stop words and using n-grams. While we believe stemming/lemmatizing and translation would be good data processing steps, we are leaving this to future work.\n",
    "\n",
    "Finally, we did detect 11 test data entries where the tokenizer identified 0 tokens. 10/11 of those entries map to the same category so you could consider a \"no data is data\" approach, but I hypothesize it will more likely lead to overfitting and would best be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description Length Statistics: \n",
      "Min:  0\n",
      "Max:  52\n",
      "Mean:  10.60846875\n",
      "Std. Dev.:  4.682643167087735\n"
     ]
    }
   ],
   "source": [
    "#Stats of number of \"words\" in each description field\n",
    "word_counter = CountVectorizer()\n",
    "word_counter.fit(train_data['description'])\n",
    "train_x = word_counter.transform(train_data['description'])\n",
    "\n",
    "num_words_per_record = train_x.sum(axis=1)\n",
    "print('Description Length Statistics: ')\n",
    "print('Min: ', np.min(num_words_per_record))\n",
    "print('Max: ', np.max(num_words_per_record))\n",
    "print('Mean: ', np.mean(num_words_per_record))\n",
    "print('Std. Dev.: ', np.std(num_words_per_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample String: \n",
      "0    Replacement Viewsonic VG710 LCD Monitor 48Watt...\n",
      "1    HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...\n",
      "Name: description, dtype: object\n",
      "\n",
      "Features: \n",
      "['10', '12v', '1410ez', '4400mah', '48watt', '48wh', '4a', '8v', 'ac', 'adapter', 'battery', 'black', 'cell', 'compaq', 'compatible', 'dv6', 'hp', 'ion', 'lcd', 'li', 'monitor', 'pavilion', 'replacement', 'vg710', 'viewsonic']\n",
      "\n",
      "Number of Occurences: \n",
      "0    [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...\n",
      "1    [1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, ...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#looking at the feature (bag of words of description field) for TWO descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "print('Sample String: ')\n",
    "sample_data = train_data.iloc[0:2]['description']\n",
    "print(sample_data)\n",
    "\n",
    "#create a dictionary from the whole trainign set\n",
    "vectorizer.fit_transform(sample_data)\n",
    "vocab_full =  vectorizer.get_feature_names()\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_full)\n",
    "bow_counts = sample_data.apply(lambda x: vectorizer.fit_transform([x]))\n",
    "\n",
    "print('')\n",
    "print('Features: ')\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print('')\n",
    "print('Number of Occurences: ')\n",
    "print(bow_counts.apply(lambda x: x.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  427297\n",
      " \n",
      "Highest frequency words: \n",
      "[('for', 165031), ('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('in', 53520), ('skin', 50501), ('and', 46959), ('decal', 43758)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('µdimm', 1), ('â³', 1), ('çelebration', 1), ('égales', 1), ('élan', 1), ('épais', 1), ('étagère', 1), ('üsküdar', 1), ('œme', 1), ('ﾠb', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  19.861536589304396\n",
      "Standard Deviation:  509.9616573544085\n",
      "Min:  1 , Number of occurences:  290634\n",
      "Max:  165031\n"
     ]
    }
   ],
   "source": [
    "#Broadening analysis to whole training set\n",
    "\n",
    "def quick_feature_analysis(feature=train_data['description'], tok_kwargs={}):\n",
    "    vectorizer = CountVectorizer(**tok_kwargs)\n",
    "    vectorizer.fit(feature)\n",
    "    train_x = vectorizer.transform(feature)\n",
    "    print('Number of features: ', train_x.shape[1])\n",
    "\n",
    "    #What are some high frequency words?\n",
    "    top_i = 10\n",
    "\n",
    "    total_occurences = zip(vectorizer.get_feature_names(), train_x.sum(axis=0).tolist()[0])\n",
    "    total_occurences_sorted = sorted(total_occurences, key=lambda x: -x[1])\n",
    "    print(' ')\n",
    "    print('Highest frequency words: ')\n",
    "    print(total_occurences_sorted[0:top_i])\n",
    "\n",
    "    print(' ')\n",
    "    print('Lowest frequency words: ')\n",
    "    print(total_occurences_sorted[-top_i:])\n",
    "\n",
    "    print(' ')\n",
    "    print('Basic Statistics of Word Frequencies: ')\n",
    "    word_freq = train_x.sum(axis=0).tolist()[0]\n",
    "    print('Mean: ', np.mean(word_freq))\n",
    "    print('Standard Deviation: ', np.std(word_freq))\n",
    "    print('Min: ', np.min(word_freq), ', Number of occurences: ', len(np.argwhere(word_freq==np.min(word_freq))))\n",
    "    print('Max: ', np.max(word_freq))\n",
    "    \n",
    "quick_feature_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  427019\n",
      " \n",
      "Highest frequency words: \n",
      "[('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('skin', 50501), ('decal', 43758), ('protective', 43434), ('filter', 40792), ('vinyl', 39550)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('µdimm', 1), ('â³', 1), ('çelebration', 1), ('égales', 1), ('élan', 1), ('épais', 1), ('étagère', 1), ('üsküdar', 1), ('œme', 1), ('ﾠb', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  18.557822954013755\n",
      "Standard Deviation:  417.8405487963014\n",
      "Min:  1 , Number of occurences:  290622\n",
      "Max:  91313\n"
     ]
    }
   ],
   "source": [
    "#What if we removed stop words?\n",
    "quick_feature_analysis(tok_kwargs={'stop_words':'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  2480461\n",
      " \n",
      "Highest frequency words: \n",
      "[('for', 165031), ('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('in', 53520), ('skin', 50501), ('and', 46959), ('decal', 43758)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('œme salon', 1), ('šâ žâ', 1), ('šã premium', 1), ('šã pãƒæ', 1), ('šã re', 1), ('šã â³', 1), ('šã â¾ãƒæ', 1), ('žâ ãƒæ', 1), ('ﾠb', 1), ('ﾠb battery', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  6.520385121959184\n",
      "Standard Deviation:  227.16310240064493\n",
      "Min:  1 , Number of occurences:  1792252\n",
      "Max:  165031\n"
     ]
    }
   ],
   "source": [
    "#What if we used n-grams?\n",
    "quick_feature_analysis(tok_kwargs={'ngram_range': (1,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with no decscription:  11\n",
      " \n",
      "Entries with empty features: \n",
      "       description         cat_full cat_1 cat_2\n",
      "58845        3 & 4    2296>3597>689  2296  3597\n",
      "161182     1-2-3-4    2296>3597>689  2296  3597\n",
      "240920           R   2296>3706>2852  2296  3706\n",
      "249402         3.0   2296>3597>2002  2296  3597\n",
      "485492         S'u    2296>3597>689  2296  3597\n",
      "528822         2.0    2296>3597>689  2296  3597\n",
      "587832     4, 5, 6   2296>2435>1941  2296  2435\n",
      "593957           S   2296>3706>1175  2296  3706\n",
      "615731         $O$    2296>3597>689  2296  3597\n",
      "707056          N+  3292>49>189>398  3292    49\n",
      "713429       X O K   2296>3597>3083  2296  3597\n"
     ]
    }
   ],
   "source": [
    "print('Number of entries with no decscription: ', len(np.argwhere(num_words_per_record==0)))\n",
    "\n",
    "print(' ')\n",
    "print('Entries with empty features: ')\n",
    "print(train_data.iloc[[i for i in np.argwhere(num_words_per_record==0)[:,0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data contains 200,000 entries with the same fields as the training data. We've loaded the dataset and performed the same preprocessing here, but have intentionally limited exploration to avoid overfitting. A quick look at the first category label distribution shows that while it also seems to be unbalanced, it appears to be unbalanced in the same manner as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cat_full</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;3813</td>\n",
       "      <td>1608</td>\n",
       "      <td>2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "      <td>2199</td>\n",
       "      <td>4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "      <td>2199</td>\n",
       "      <td>4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "      <td>1608</td>\n",
       "      <td>4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "      <td>3292</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description             cat_full  \\\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>3813   \n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12   \n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12   \n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221   \n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231   \n",
       "\n",
       "  cat_1 cat_2  \n",
       "0  1608  2320  \n",
       "1  2199  4592  \n",
       "2  2199  4592  \n",
       "3  1608  4269  \n",
       "4  3292   114  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('https://github.com/up-lab/rakuten-data-challenge/raw/master/rdc-catalog-test.tsv', header=0, names=['description', 'cat_full'], sep='\\t', )\n",
    "test_data['cat_1'] = test_data['cat_full'].apply(lambda x: x.split('>')[0])\n",
    "test_data['cat_2'] = test_data['cat_full'].apply(lambda x: x.split('>')[1] if (len(x.split('>'))>1) else np.nan)\n",
    "test_data.dropna(subset=['description','cat_1'], inplace=True)\n",
    "print('Number of rows: ', test_data.shape[0])\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_1\n",
       "1208    0.000605\n",
       "1395    0.020385\n",
       "1608    0.105870\n",
       "2075    0.023325\n",
       "2199    0.127690\n",
       "2296    0.041095\n",
       "3093    0.006155\n",
       "3292    0.250175\n",
       "3625    0.039045\n",
       "3730    0.010055\n",
       "4015    0.330875\n",
       "4238    0.028400\n",
       "4564    0.005855\n",
       "92      0.010470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at how balanaced the test set is\n",
    "test_data.groupby('cat_1').apply(len)/len(test_data['cat_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straightforward metric is of course accuracy. Accuracy simply tells us the percentage that the classifier predicts the correct label.\n",
    "\n",
    "An evaluation tool we will look at here is a confusion matrix (at least for the first level of categorization). The confusion matrix is a grid showing number/percentage of each predicted labels vs the actual labels. This may be advantageous for debugging purposes (e.g. are there two classes that are often confused for one another?).\n",
    "\n",
    "Other performance metrics should be considered depending on system design intentions. If this is a human-in-the-loop system and the accuracy is only ok, I would recommend another performance metric here that measures how well the classifier understands its' ability to predict the output. In other words, how accurate is the classifiers' prediction probability? One example of this type of metric would be the Brier score. In this system, if the prediction probabilities are determined to be reliable, a confidence threshold could be set and all predictions whose probability is below that threshold would be flagged for human validation and feedback. This type of metric was not evaluated here but is strongly recommended after further use case review with stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for accuracy\n",
    "def display_performance(classifier, test_x, test_y, train_x=[], train_y=[]):\n",
    "    \"\"\"\n",
    "    Prints accuracy and confusion matrix for specified classifier and test set.\n",
    "    Displays the confusion matrix. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if (train_x.shape[0]>0) & (train_y.shape[0]>0):\n",
    "        train_accuracy = classifier.score(train_x, train_y)\n",
    "        print('Overall Training Set Accuracy: ', train_accuracy)\n",
    "        cv_scores = cross_val_score(classifier, train_x, train_y, cv=5)\n",
    "        print('Cross-validated Training Set Accuracy: {:.2f} +/- {:.2f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    accuracy = classifier.score(test_x, test_y)\n",
    "    \n",
    "    print('Test Set Accuracy: ', accuracy)\n",
    "    \n",
    "    predictions = classifier.predict(test_x)\n",
    "    num_labels = len(classifier.classes_)\n",
    "    cf_matrix = np.zeros((num_labels, num_labels))\n",
    "    labels = np.unique(test_y)\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        label_actual = test_y[i]\n",
    "        label_actual_idx = np.argwhere(labels==label_actual)[0]\n",
    "        predict_label_idx = np.argwhere(labels==prediction)[0]\n",
    "        cf_matrix[label_actual_idx, predict_label_idx] += 1\n",
    "        cf_matrix_norm = normalize(cf_matrix, axis=1, norm='l1')\n",
    "\n",
    "    sns.heatmap(cf_matrix_norm, xticklabels=labels, yticklabels=labels, cmap=\"YlGnBu\")\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Parameter Tuning\n",
    "\n",
    "Finally, we build a machine learning classifier. For this task, we will use a multinomial Naïve Bayes classifier. As discussed in data analysis, the features will be a count vector of the tokens generated from the product descriptions. The labels will be the product categories. This section shows the implementation of the classifier model, model tuning and performance of level 1 and level 2 category classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes Multinomial Classifier - Category Level 1 \n",
    "\n",
    "First, we look at the classifier performance for level 1 product category classification.\n",
    "\n",
    "For a very simple classifier setup (i.e. no additional data processing beyond basic token count vectorizing and default parameters for the scikit learn Bayes multinomial classifier), we show a classification accuracy of 85.0%.\n",
    "\n",
    "The confusion matrix breaks down the performance of each label to give us more details about performance. The rows show the actual prediction label and the columns shows the classifier's prediction. The color of the grid denotes the density of the actual/predicted label. A perfect classifier would show only the diagonal populated. This confusion matrix is normalized by row. There are several interesting aspects to note in this confusion matrix. For the \"1208\" labels, the classifier almost always predicted \"4015\". For the \"4015\" labels, the classifier performs nearly perfectly. Most incorrect predictions predict the \"4015\" label. If we look back to the data analysis where we looked at the distribution of training labels, we see that the \"4015\" label comprised a large portion of the training set. I hypothesize that because the Bayes classifier is based on Bayes theorem which incorporates the probability of a label, that removing that variable (the fit prior) in the classifier will result in better performance.\n",
    "\n",
    "Finally, we do some early (and minimal) tuning of the classifier to see if there are some better parameter choices for our machine learning model. We perform a grid search of the following parameters: the removing/not removing stop words from the product descriptions, use of 1- or 1- and 2- grams and presence/absence of the fit prior in the multinomial Bayes classifier. This grid search revealed the best parameters were using 1- and 2- grams, not removing stop words and removing fit prior from the Bayes calculation, which yielded accuracy of 87.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Training Set Accuracy:  0.880355\n",
      "Cross-validated Training Set Accuracy: 0.86 +/- 0.00\n",
      "Test Set Accuracy:  0.85021\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#setting up a pipeline to ease parameter tuning later\n",
    "bayes_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB(),)])\n",
    "bayes_pipeline.fit(train_data['description'], train_data['cat_1'])\n",
    "display_performance(bayes_pipeline.named_steps['classifier'], \n",
    "                    bayes_pipeline.named_steps['vectorizer'].transform(test_data['description']), test_data['cat_1'], \n",
    "                    bayes_pipeline.named_steps['vectorizer'].transform(train_data['description']), train_data['cat_1']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best train score after grid search:  0.8929525\n",
      "\n",
      "classifier__fit_prior: False\n",
      "vectorizer__ngram_range: (1, 2)\n",
      "vectorizer__stop_words: None\n",
      "\n",
      "Best test score after grid search:  0.8783\n"
     ]
    }
   ],
   "source": [
    "#grid search on a few different parameters we can tune\n",
    "params = {'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "          'vectorizer__stop_words': ('english', None),\n",
    "          'classifier__fit_prior': (True, False),\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(bayes_pipeline, params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_data['description'], train_data['cat_1'])\n",
    "print('Best train score after grid search: ', grid_search.best_score_)\n",
    "print('')\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid_search.best_params_[param_name]))\n",
    "\n",
    "print('')\n",
    "print('Best test score after grid search: ', grid_search.score(test_data['description'], test_data['cat_1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes Multinomial Classifier - Category Level 2\n",
    "\n",
    "Next, we look at the classifier performance for level 2 product category classification. Our simple classifier setup (i.e. no additional data processing beyond basic token count vectorizing and default parameters for the scikit learn Bayes multinomial classifier), we show a classification accuracy of 75.2%. It is unsurprising that the accuracy would decrease since the number of classes increased from 14 to 109. One interesting idea for future work would be the progressive use of previous category as a feature. Previously we mentioned a potential human-in-the-loop system where the classification was human-assisted. In this example, if we were reasonably confident in the first level category either through the system's confidence or confirmation from the user, that category might be used as a feature for better second level category classification.\n",
    "\n",
    "The confusion matrix isn't shown here because there are so many classes that its' usefulness is questionable.\n",
    "\n",
    "Finally, we did the same minimal grid search of optimal parameters for the classifier system. This grid search revealed the best parameters were using 1- and 2- grams, removing stop words and removing fit prior from the Bayes calculation, which yielded accuracy of 79.6%. This selection of parameters was pretty close to the category level 1 parameters except now it was better to include the stop word removal in data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.752155\n"
     ]
    }
   ],
   "source": [
    "bayes_pipeline2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB(),)])\n",
    "\n",
    "train_data_level2_cleaned = train_data.fillna('')\n",
    "test_data_level2_cleaned = test_data.fillna('')\n",
    "bayes_pipeline2.fit(train_data_level2_cleaned['description'], train_data_level2_cleaned['cat_2'])\n",
    "\n",
    "print('Accuracy: ', bayes_pipeline2.score(test_data_level2_cleaned['description'], test_data_level2_cleaned['cat_2']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadixon/Documents/coding/misc/censusbureau/env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#grid search on a few different parameters we can tune\n",
    "params = {'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "          'vectorizer__stop_words': ('english', None),\n",
    "          'classifier__fit_prior': (True, False),\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(bayes_pipeline2, params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_data_level2_cleaned['description'], train_data_level2_cleaned['cat_2'])\n",
    "print('Best train score after grid search: ', grid_search.best_score_)\n",
    "print('')\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid_search.best_params_[param_name]))\n",
    "\n",
    "print('')\n",
    "print('Best test score after grid search: ', grid_search.score(test_data_level2_cleaned['description'], test_data_level2_cleaned['cat_2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook shows an early attempt to address a key stakeholder issue which is the classification of products from product descriptions. We present some data analysis to show some characteristics of our data features and labels. We show that a straightforward performance metric for a multilabel classification system is accuracy, but leave open the possibility of performance metrics that account for prediction probabilities. Finally, we evaluate the performance of a multinomial Naïve Bayes classifier for text classification which initially achieved a 85.0% accuracy for first level category classification and 75.2% accuracy for second level category classification. We show that benefits of parameter tuning which sees a 2.8% accuracy improvement at the first level category classification and a 4.4% accuracy improvement at the second level category classification.\n",
    "\n",
    "There are several avenues for future work in this project, but our top recommendations would include refinement of performance metrics based on further stakeholder conversations, more feature processing including stemming/lemmatization and English translation and a deeper investigation of text classification choices beyond the Bayes classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "censusbureau",
   "language": "python",
   "name": "censusbureau"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
